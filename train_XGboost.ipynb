{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner_mark</th>\n",
       "      <th>Generation_first</th>\n",
       "      <th>Legendary_first</th>\n",
       "      <th>Generation_second</th>\n",
       "      <th>Legendary_second</th>\n",
       "      <th>HP_diff</th>\n",
       "      <th>Attack_diff</th>\n",
       "      <th>Defense_diff</th>\n",
       "      <th>Sp. Atk_diff</th>\n",
       "      <th>Sp. Def_diff</th>\n",
       "      <th>Speed_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-20</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>-15</td>\n",
       "      <td>10</td>\n",
       "      <td>-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-39</td>\n",
       "      <td>-18</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-20</td>\n",
       "      <td>-35</td>\n",
       "      <td>10</td>\n",
       "      <td>-45</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-37</td>\n",
       "      <td>-80</td>\n",
       "      <td>-50</td>\n",
       "      <td>10</td>\n",
       "      <td>-50</td>\n",
       "      <td>-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>-105</td>\n",
       "      <td>105</td>\n",
       "      <td>-160</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>-15</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "      <td>-65</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>-20</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>124</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Winner_mark  Generation_first  Legendary_first  Generation_second  \\\n",
       "0                2                 2                0                  3   \n",
       "1                2                 5                1                  5   \n",
       "2                2                 2                0                  5   \n",
       "3                2                 2                0                  5   \n",
       "4                1                 1                0                  2   \n",
       "...            ...               ...              ...                ...   \n",
       "49995            1                 5                1                  1   \n",
       "49996            1                 5                0                  5   \n",
       "49997            2                 3                0                  3   \n",
       "49998            1                 1                0                  1   \n",
       "49999            1                 1                0                  1   \n",
       "\n",
       "       Legendary_second  HP_diff  Attack_diff  Defense_diff  Sp. Atk_diff  \\\n",
       "0                     0      -20           -6            10           -15   \n",
       "1                     1        0          -39           -18            18   \n",
       "2                     0      -20          -35            10           -45   \n",
       "3                     0      -37          -80           -50            10   \n",
       "4                     0       50           50          -105           105   \n",
       "...                 ...      ...          ...           ...           ...   \n",
       "49995                 0       70           80            30            80   \n",
       "49996                 0       25           30             0           -15   \n",
       "49997                 0      -13          -65            40            25   \n",
       "49998                 0       15           -5           -20           -40   \n",
       "49999                 0        8           24            28           124   \n",
       "\n",
       "       Sp. Def_diff  Speed_diff  \n",
       "0                10         -19  \n",
       "1                39           0  \n",
       "2                10           0  \n",
       "3               -50         -28  \n",
       "4              -160          50  \n",
       "...             ...         ...  \n",
       "49995            95          30  \n",
       "49996             5           8  \n",
       "49997            10         -25  \n",
       "49998             0          55  \n",
       "49999            80          65  \n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_df = pd.read_csv('./pokemon_df_rf.csv')\n",
    "pokemon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pokemon_df['Winner_mark']\n",
    "X = pokemon_df.drop('Winner_mark', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:03:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { gammar } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:03:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gammar=0,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.08, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.75,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier( # check : 설정값\n",
    "    n_estimators = 100, \n",
    "    learning_rate = 0.08,  \n",
    "    gammar = 0, \n",
    "    subsample = 0.75,\n",
    "    colsample_bytree = 1,\n",
    "    max_depth = 7 \n",
    ") \n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- train accuracy_score : 0.95888\n",
      "- test  accuracy_score : 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95888"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = xgb.predict(X_train)\n",
    "pred_test = xgb.predict(X_test)\n",
    "\n",
    "print('- train accuracy_score :',accuracy_score(y_train, pred_train))\n",
    "print('- test  accuracy_score :', accuracy_score(y_test, pred_test))\n",
    "\n",
    "xgb.score(X_train, y_train) # check : accuracy랑 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02011341, 0.02446071, 0.02230691, 0.0279221 , 0.02320727,\n",
       "       0.04546936, 0.02209206, 0.01891296, 0.01839117, 0.7771241 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = xgb.feature_importances_\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE(Mean Absolute Error) \n",
    "- 실제값과 예측값 차이(Error)를 절대값으로 변환해 평균화 \n",
    "- MAE는 에러에 절대값을 취하기 때문에 에러의 크리 그대로 반영됨 \n",
    "- 에러에 따른 손실이 선형적으로 올라갈 때 적합\n",
    "- 이상치가 많을 때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check : mae - 실제값과 예측값 차이(Error)를 절대값으로 변환해 평균화 \n",
    "mae = mean_absolute_error(y_test, pred_test)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
